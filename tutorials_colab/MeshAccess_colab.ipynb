{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MICrONS Neuron Mesh Download\n",
    "This tutorial walks through the key functions needed to access the MICrONS dataset programmatically and highlights key resources within it. While this tutorial is written for the MICrONS dataset specifically, the underlying technology (CAVE) is being used for multiple connectomics dataset. So, the interface presented here can be used to query them as well.\n",
    "\n",
    "__This notebook is made to run in Google Colab. Each time your start the remote kernel, you will need to reinstall CAVE and add your token__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAVEclient and setup\n",
    "\n",
    "The __CAVEclient__ is a python library that facilitates communication with a CAVE system. It can be install with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q caveclient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and imported like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caveclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAVE account setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to manage server traffic, every user needs to create a CAVE account and download a user token to access CAVE's services programmatically. The CAVE infrastructure can be read about in more detail on our preprint. The MICrONS data is publicly available which means that no extra permissions need to be given to a new user account to access the data. Bulk downloads of some static data are also available without an account on MICrONs Explorer.\n",
    "\n",
    "__A Google account (or Google-enabled account) is required to create a CAVE account.__\n",
    "\n",
    "Go to: https://global.daf-apis.com/auth/api/v1/user/token to view a list of your existing tokens\n",
    "\n",
    "If you have never made a token before:\n",
    "1. go here: https://minnie.microns-daf.com/materialize/views/datastack/minnie65_public to accept terms of service\n",
    "2. then go here https://global.daf-apis.com/auth/api/v1/create_token to create a new token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set or save your token\n",
    "\n",
    "From the website that just opened up, paste your token here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_token = \"PASTE_TOKEN_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from meshparty import trimesh_io, trimesh_vtk\n",
    "import cloudvolume \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inititalize the CAVEclient\n",
    "datastack_name = \"minnie65_public\"\n",
    "\n",
    "client = caveclient.CAVEclient(datastack_name, auth_token=my_token)\n",
    "\n",
    "# specify the materialization version, for consistency across time\",\n",
    "client.version = 943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Versioning note:__ We use version 943 is this notebook because it corresponds with the most recent static segmentation, which is what you see on [microns-explorer.org](https://www.microns-explorer.org/gallery-mm3)\n",
    "\n",
    "The most recent public version at the time of writing (2/1/2025) is __version 1300__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Mesh?\n",
    "A mesh is a set of vertices connected via triangular faces to form a 3 dimensional representation of the outer membrane of a neuron, glia or nucleus.\n",
    "\n",
    "### Meshes can either be static or dynamic:\n",
    "##### Static:\n",
    "- pros: smaller files thus easier to work with, multiple levels of detail (lod) which can be accessed (example below)\n",
    "- cons: may include false gaps and merges from self contacts, updated less frequently\n",
    "\n",
    "##### Dynamic:\n",
    "- pros: highly detailed thus more reflective of biological reality and backed by proofreading infrastructure CAVE (Connectome Annotation Versioning Engine)\n",
    "- cons: much larger files, only one level of detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to access dynamic meshes, you can query the segmentation source from the info client\n",
    "client.info.segmentation_source()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this can be used to initialize a cloudvolume object\n",
    "cv = cloudvolume.CloudVolume(client.info.segmentation_source(), progress=False, use_https=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a root_id, __CloudVolume__ can be used to retrieve the mesh. \n",
    "`cloudvolume.mesh.get()` returns a dictionary with the neuron segment id as the key and the mesh as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example: pyramidal cell in v943\n",
    "example_cell_id = 864691135572530981\n",
    "%time mesh = cv.mesh.get(example_cell_id)[example_cell_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned mesh includes:\n",
    "* vertices : Nx3 [x, y, z] positions in nm\n",
    "* faces: Kx3 [i, j, k] indices into vertices that describe the triangular meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(mesh.vertices.shape, mesh.faces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since downloading meshes can take some time, particularly for these dynamic meshes,\n",
    "it is convient to cache them on disk.     \n",
    "     \n",
    "To facilitate the analysis of meshes, we developed a package called __MeshParty__ that we will use here to enable a cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to enable a cache, create a MeshMeta object\n",
    "mm = trimesh_io.MeshMeta(cv_path = client.info.segmentation_source(),\n",
    "                         disk_cache_path='minnie65_meshes',\n",
    "                         map_gs_to_https=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a mesh like this and it will be cached in memory and in disk in case you need it again.    \n",
    "Restart the kernel and run the below cells again to see the difference.   \n",
    "\n",
    "You'll find the mesh file saved as an hdf5 file in the \"minnie65_meshes\"\n",
    "subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = mm.mesh(seg_id=example_cell_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MeshParty object has more useful properties and attributes\n",
    "such as:\n",
    "* a scipy.csgraph sparse graph object (mesh.csgraph)\n",
    "*  a networkx graph object (mesh.nxgraph) \n",
    "\n",
    "Read more about what you can do with MeshParty on its [Documentation](https://meshparty.readthedocs.io/en/latest/?badge=latest).\n",
    "\n",
    "In particular it lets you associate _skeletons_, and _annotations_ onto the mesh into a \"meshwork\" object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Meshes    \n",
    "The meshes that are available in the visualization on microns-explorer.org are faster because they are static and have been downsampled multiple times. However, this comes with the drawback of being less biologically accurate.\n",
    "\n",
    "Level of detail is controlled with optional argument, where `lod=0` is the highest level of detail\n",
    "\n",
    "we can access one of these downsampled static meshes by setting the path here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Previous versions of this tutorial have used v117 meshes, with the following path\n",
    "# cv = cloudvolume.CloudVolume(\"precomputed://gs://iarpa_microns/minnie/minnie65/seg\", use_https=True)\n",
    "\n",
    "cv = cloudvolume.CloudVolume(\"precomputed://gs://iarpa_microns/minnie/minnie65/seg_m943\", use_https=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the cloud volume interface is the same but it is a faster initial download \n",
    "%time mesh = cv.mesh.get(example_cell_id, lod=3)[example_cell_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# as you can see the meshes aren't exactly the same as before. They because they have not been downsampled\n",
    "mesh.vertices.shape, mesh.faces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the Static meshes are available in 3 levels of detail, this covers two orders of magnitude of detail\n",
    "which is what neuroglancer leverages to efficiently load the data at the resolution necessary to render the current scene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lod in range(4):\n",
    "    mesh = mesh = cv.mesh.get(example_cell_id, lod=lod)[example_cell_id]\n",
    "    print(f\"level of detail {lod}: n_verts: {mesh.vertices.shape[0]} n_faces: {mesh.faces.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have the neuron mesh, at your chosen level of detail, downloaded and ready to use locally. For next steps, consider:\n",
    "\n",
    "1. Mesh repair and visualization [examples with __meshparty__](https://meshparty.readthedocs.io/en/latest/guide/visualization.html) \n",
    "2. Mesh simplification and analysis [from our friends at __Navis__](https://navis-org.github.io/navis/generated/gallery/4_remote/tutorial_remote_02_microns/)\n",
    "3. Exporting the meshes into Neuron, or simulation program of your choice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
