{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MICrONS Neuron Mesh Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from caveclient import CAVEclient\n",
    "from meshparty import trimesh_io, trimesh_vtk\n",
    "import cloudvolume \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inititalize the CAVEclient\n",
    "client = CAVEclient('minnie65_public')\n",
    "\n",
    "# specify the materialization version, for consistency across time\",\n",
    "client.version = 943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Mesh?\n",
    "A mesh is a set of vertices connected via triangular faces to form a 3 dimensional representation of the outer membrane of a neuron, glia or nucleus.\n",
    "\n",
    "### Meshes can either be static or dynamic:\n",
    "##### Static:\n",
    "- pros: smaller files thus easier to work with, multiple levels of detail (lod) which can be accessed (example below)\n",
    "- cons: may include false gaps and merges from self contacts, updated less frequently\n",
    "\n",
    "##### Dynamic:\n",
    "- pros: highly detailed thus more reflective of biological reality and backed by proofreading infrastructure CAVE (Connectome Annotation Versioning Engine)\n",
    "- cons: much larger files, only one level of detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graphene://https://minnie.microns-daf.com/segmentation/table/minnie65_public'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to access dynamic meshes, you can query the segmentation source from the info client\n",
    "client.info.segmentation_source()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this can be used to initialize a cloudvolume object\n",
    "cv = cloudvolume.CloudVolume(client.info.segmentation_source(), progress=False, use_https=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a root_id, __CloudVolume__ can be used to retrieve the mesh. \n",
    "`cloudvolume.mesh.get()` returns a dictionary with the neuron segment id as the key and the mesh as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "CPU times: total: 35.1 s\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "# Example: pyramidal cell in v943\n",
    "example_cell_id = 864691135572530981\n",
    "%time mesh = cv.mesh.get(example_cell_id)[example_cell_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned mesh includes:\n",
    "* vertices : Nx3 [x, y, z] positions in nm\n",
    "* faces: Kx3 [i, j, k] indices into vertices that describe the triangular meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4390777, 3) (8761561, 3)\n"
     ]
    }
   ],
   "source": [
    "print(mesh.vertices.shape, mesh.faces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since downloading meshes can take some time, particularly for these dynamic meshes,\n",
    "it is convient to cache them on disk.     \n",
    "     \n",
    "To facilitate the analysis of meshes, we developed a package called __MeshParty__ that we will use here to enable a cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to enable a cache, create a MeshMeta object\n",
    "mm = trimesh_io.MeshMeta(cv_path = client.info.segmentation_source(),\n",
    "                         disk_cache_path='minnie65_meshes',\n",
    "                         map_gs_to_https=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a mesh like this and it will be cached in memory and in disk in case you need it again.    \n",
    "Restart the kernel and run the below cells again to see the difference.   \n",
    "\n",
    "You'll find the mesh file saved as an hdf5 file in the \"minnie65_meshes\"\n",
    "subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Meshes: 100%|████████████████████████████████████████████████████████████████| 1/1 [00:52<00:00, 52.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mesh = mm.mesh(seg_id=example_cell_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MeshParty object has more useful properties and attributes\n",
    "such as:\n",
    "* a scipy.csgraph sparse graph object (mesh.csgraph)\n",
    "*  a networkx graph object (mesh.nxgraph) \n",
    "\n",
    "Read more about what you can do with MeshParty on its [Documentation](https://meshparty.readthedocs.io/en/latest/?badge=latest).\n",
    "\n",
    "In particular it lets you associate _skeletons_, and _annotations_ onto the mesh into a \"meshwork\" object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Meshes    \n",
    "The meshes that are available in the visualization on microns-explorer.org are faster because they are static and have been downsampled multiple times. However, this comes with the drawback of being less biologically accurate.\n",
    "\n",
    "Level of detail is controlled with optional argument, where `lod=0` is the highest level of detail\n",
    "\n",
    "we can access one of these downsampled static meshes by setting the path here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Previous versions of this tutorial have used v117 meshes, with the following path\n",
    "# cv = cloudvolume.CloudVolume(\"precomputed://gs://iarpa_microns/minnie/minnie65/seg\", use_https=True)\n",
    "\n",
    "cv = cloudvolume.CloudVolume(\"precomputed://gs://iarpa_microns/minnie/minnie65/seg_m943\", use_https=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 1.43 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# the cloud volume interface is the same but it is a faster initial download \n",
    "%time mesh = cv.mesh.get(example_cell_id, lod=3)[example_cell_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58739, 3), (101632, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you can see the meshes aren't exactly the same as before. They because they have not been downsampled\n",
    "mesh.vertices.shape, mesh.faces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the Static meshes are available in 3 levels of detail, this covers two orders of magnitude of detail\n",
    "which is what neuroglancer leverages to efficiently load the data at the resolution necessary to render the current scene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level of detail 0: n_verts: 5234626 n_faces: 10297114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level of detail 1: n_verts: 1459352 n_faces: 2830368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level of detail 2: n_verts: 253182 n_faces: 474382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level of detail 3: n_verts: 58739 n_faces: 101632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for lod in range(4):\n",
    "    mesh = mesh = cv.mesh.get(example_cell_id, lod=lod)[example_cell_id]\n",
    "    print(f\"level of detail {lod}: n_verts: {mesh.vertices.shape[0]} n_faces: {mesh.faces.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have the neuron mesh, at your chosen level of detail, downloaded and ready to use locally. For next steps, consider:\n",
    "\n",
    "1. Mesh repair and visualization [examples with __meshparty__](https://meshparty.readthedocs.io/en/latest/guide/visualization.html) \n",
    "2. Mesh simplification and analysis [from our friends at __Navis__](https://navis-org.github.io/navis/generated/gallery/4_remote/tutorial_remote_02_microns/)\n",
    "3. Exporting the meshes into Neuron, or simulation program of your choice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microns2025",
   "language": "python",
   "name": "microns2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
